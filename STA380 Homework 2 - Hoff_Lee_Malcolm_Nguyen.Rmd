---
title: "Pred Modeling Part 2 - Exercises 2"
author: "Ryan Hoff, Won Lee, Sam Malcolm, Cory Nguyen"
date: "8/20/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

### 1: Flights at ABIA


```{r}
# For flights that are delayed, which holidays see a statistically significant increase in logDelay time?
library(ggplot2)
library(dplyr)
abia <- read.csv('https://raw.githubusercontent.com/jgscott/STA380/master/data/ABIA.csv', header=TRUE)

# Ignore all flights with missing departure delays or no delay
abia <- abia[(complete.cases(abia$DepDelay)) & abia$DepDelay > 0,]
attach(abia)
set.seed(33)

# Basic EDA
# hist(DepDelay)
abia$logDelay = log(DepDelay)
# hist(abia$logDelay)

# Distinguish by carrier
# table(UniqueCarrier)
# barplot(table(UniqueCarrier))

# Christmas season: 12/22 - 12/25
christmas.days = which(Month==12 & DayofMonth<=25 & DayofMonth>=22)
# Memorial season: 5/23 - 5/26
memorial.days = which(Month==5 & DayofMonth<=26 & DayofMonth>=23)
# Labor season: 8/28 - 9/1
labor.days = which((Month==8 & DayofMonth>=28) | (Month==9 & DayofMonth<=1))
# Thanksgiving season: 11/24 - 11/27
thanksgiving.days = which(Month==11 & DayofMonth<=27 & DayofMonth>=24)
# Easter season: 3/20 - 3/23
easter.days = which(Month==3 & DayofMonth<=23 & DayofMonth>=20)
# July 4 season: 7/1 - 7/4
july4.days = which((Month==7 & DayofMonth>=1) | (Month==7 & DayofMonth<=4))
# All holidays
holiday.days = c(christmas.days,memorial.days,labor.days,thanksgiving.days,easter.days,july4.days)
par(mfrow = c(2,3))
abia.christmas = abia[christmas.days,]
# barplot(table(abia.christmas$UniqueCarrier), main = 'Christmas Season')
abia.memorial = abia[memorial.days,]
# barplot(table(abia.memorial$UniqueCarrier), main = 'Memorial Day Season')
abia.labor = abia[labor.days,]
# barplot(table(abia.labor$UniqueCarrier), main = 'Labor Day Season')
abia.thanksgiving = abia[thanksgiving.days,]
#barplot(table(abia.thanksgiving$UniqueCarrier), main = 'Thanksgiving Season')
abia.easter = abia[easter.days,]
#barplot(table(abia.easter$UniqueCarrier), main = 'Easter Season')
abia.july4 = abia[july4.days,]
#barplot(table(abia.july4$UniqueCarrier), main = 'July 4th Season')
par(mfrow = c(1,1))
abia.regular = abia[-holiday.days,]
#barplot(table(abia.regular$UniqueCarrier), main = 'Normal Days')
detach(abia)

# mean(abia.regular$logDelay)
abia.holidays = list(abia.christmas, abia.memorial, abia.labor, abia.easter, abia.thanksgiving, abia.july4)
holidays = c('Christmas', 'Memorial', 'Labor', 'Easter', 'Thanksgiving', 'July 4')
p.vals = list()
i = 1
for(item in abia.holidays){
  a = t.test(abia.regular$logDelay, item$logDelay)
  p.vals[i] = a[3]
  i = i + 1
}

sigholidays = cbind(holidays, p.vals)
# Christmas, Labor Day, Thanksgiving (Easter (fails at .01 level))

```




```{r}
abia <- read.csv('https://raw.githubusercontent.com/jgscott/STA380/master/data/ABIA.csv', header=TRUE)
abia <- abia[(complete.cases(abia$DepDelay)),]
attach(abia)
set.seed(33)

# Christmas season: 12/22 - 12/25
christmas.days = which(Month==12 & DayofMonth<=25 & DayofMonth>=22)
# Labor season: 8/28 - 9/1
labor.days = which((Month==8 & DayofMonth>=28) | (Month==9 & DayofMonth<=1))
# Thanksgiving season: 11/24 - 11/27
thanksgiving.days = which(Month==11 & DayofMonth<=27 & DayofMonth>=24)

abia.christmas = abia[christmas.days,]
abia.labor = abia[labor.days,]
abia.thanksgiving = abia[thanksgiving.days,]
detach(abia)

# Keep most frequent airlines ( > 5 flights for each holiday)
# sort(table(abia.christmas$UniqueCarrier) + table(abia.labor$UniqueCarrier) + table(abia.thanksgiving$UniqueCarrier))
keep = c('WN', 'AA', 'CO', 'DL', 'B6', 'OH', 'YV', 'OO', 'F9', '9E', 'UA', 'US')
airlines = c('Southwest', 'American', 'Continental', 'Delta', 'JetBlue', 'PSA', 'Mesa', 'Skywest', 'Frontier', 'Endeavor', 'United', 'US Airways')

abia.xmas.filt = abia.christmas[abia.christmas$UniqueCarrier %in% keep,] %>% droplevels()
abia.labor.filt = abia.labor[abia.labor$UniqueCarrier %in% keep,] %>% droplevels()
abia.thanks.filt = abia.thanksgiving[abia.thanksgiving$UniqueCarrier %in% keep,] %>% droplevels()

# Create a table with mean and sd for departure delays for each holiday
holiday.mat = matrix(, nrow = length(keep), ncol = 7)

row = 1
for(item in keep){
  col = 1
  holiday.mat[row,col] = airlines[row]
  col = 2
  xmas.carrier = subset(abia.xmas.filt, UniqueCarrier == item)
  thanks.carrier = subset(abia.thanks.filt, UniqueCarrier == item)
  labor.carrier = subset(abia.labor.filt, UniqueCarrier == item)
  holiday.mat[row, col] = mean(xmas.carrier$DepDelay)
  col = 3
  holiday.mat[row, col] = sd(xmas.carrier$DepDelay)
  col = 4
  holiday.mat[row, col] = mean(thanks.carrier$DepDelay)
  col = 5
  holiday.mat[row, col] = sd(thanks.carrier$DepDelay)
  col = 6
  holiday.mat[row, col] = mean(labor.carrier$DepDelay)
  col = 7
  holiday.mat[row, col] = sd(labor.carrier$DepDelay)
  row = row + 1
}

holiday.df = as.data.frame.matrix(holiday.mat) 
names(holiday.df) <- c("airline", "xmas_mean", "xmas_sd", "thanks_mean", "thanks_sd", "labor_mean", "labor_sd")

# Plot those bad boys
ggplot(holiday.df, aes(x = reorder(airline,as.numeric(as.character(labor_mean)),mean), y = as.numeric(as.character(labor_mean)), fill = as.numeric(as.character(labor_mean)))) +
  geom_col(fill = c('#70DF8F', '#70DF8F', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#FF9797')) +
  ylim(-10, 60) +
  labs(x = 'Airline', y = 'Average Departure Delay (mins)', title = 'Average Departure Delays - Labor Day', subtitle = 'Flights departing within 3 days prior to and including the holiday') +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

ggplot(holiday.df) + 
  aes(x = reorder(airline,as.numeric(as.character(thanks_mean)),mean), y = as.numeric(as.character(thanks_mean)), fill = as.numeric(as.character(labor_mean))) +
  geom_col(fill = c('#70DF8F', '#70DF8F', '#70DF8F', '#70DF8F', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#8C8C8C', '#FF9797')) +
  ylim(-10, 60) +
  labs(x = 'Airline', y = 'Average Departure Delay (mins)', title = 'Average Departure Delays - Thanksgiving', subtitle = 'Flights departing within 3 days prior to and including the holiday') +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))

ggplot(holiday.df) + 
  aes(x = reorder(airline,as.numeric(as.character(xmas_mean)),mean), y = as.numeric(as.character(xmas_mean)), fill = as.numeric(as.character(labor_mean))) +
  geom_col(fill = c('#8C8C8C', '#8C8C8C', '#FF9797', '#FF9797', '#FF9797', '#FF9797', '#DF6666', '#DF6666', '#DF6666', '#DF6666', '#BF5757', '#9F4848')) +
  ylim(-10, 60) +
  labs(x = 'Airline', y = 'Average Departure Delay (mins)', title = 'Average Departure Delays - Christmas', subtitle = 'Flights departing within 3 days prior to and including the holiday') +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))


```


##### Which airlines experience the longest departure delays during travel holidays?

We wanted to find the airlines that experienced the most and least delays around the holidays. We first tested which holidays experienced statistically significant departure delays. We then plotted the mean departure delays by airline for these holidays. We experimented with representing other statistics such as median departure delays (to help offset effect of outliers) and rate of flights delayed (to show how likely you were to experience a delay at all). However, we felt that mean departure delay still captured that information well for each airline (especially in proportion to one another). We also determined that the most utility would come from knowing if you would experience a major delay, so the magnitude of delay is important to represent. We felt this was an informative but interpretable way to portray it. 


### 2. - Author Attribution 

##### Naive Bayes : 63.4% out-of-sample accuracy
##### PCR:          63.8% out-of-sample accuracy

The two author attribution models that we built were based on the Naïve Bayes classifier and principal components regression using ridge regression. Based on the nature of the data (training and test sets had dimensions of at least 2500 x 3000), our first instinct was to choose a quick but reliable model to help us find a baseline accuracy to improve on. Since there were 50 authors in the data, we first chose to use a Multiple Naïve Bayes model. This model is both quick and reliable, and comes with the advantage of being able to handle multiple classes. The out-of-sample accuracy of this model is 63.4%. 

Our next choice for model fitting was principle components regression using ridge regression. Since the number of features exceeded 3000, we wanted to employ a model that implemented dimensionality reduction. Our use of PCR completes this goal twofold, once when using PCA, and again when using ridge regression to “zero out” unimportant features when building a model for each author. This method will reduce the impact of noise on the models. The out-of-sample accuracy of this model when using the first 600 principal components is 63.8%, barely edging out Naïve Bayes. 

In comparing these models, their accuracies are about the same. Naïve Bayes will run faster, but each author’s PCR model can be further analyzed to decide if they have patterns in their writing based on the significance of certain loadings in PCR.

It's interesting that - at least with these two models - the ability to predict certain authors is fairly consistent. There are some differences, but the authors that were the most and least predictable were generally consistent. There were even a few that the models were very successful at predicting.


```{r}
library(maptpx)
library(wordcloud)
library(tm)
library(glmnet)
set.seed(33)

# Directories into single corpus
author_dirs = Sys.glob('ReutersC50/C50train/*')
file_list = NULL
labels = NULL

# Pull author and file names
for(author in author_dirs) {
  author_name = substring(author, first=21)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  labels = append(labels, rep(author_name, length(files_to_add)))
}

# Define function to read plaintext documents in English
readerPlain = function(fname){
  readPlain(elem=list(content=readLines(fname)), 
            id=fname, language='en') }

# Read in and rename docs
all_docs = lapply(file_list, readerPlain)
all_docsAuthor = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))
names(all_docsAuthor) = labels

# Create text mining corpus, name using author names
docRaw = VCorpus(VectorSource(all_docs)) # Corpus function refuses to be renamed, even though it's
# the example used in the notes and in the github examples. VCorpus or Vcorpus needed.
# It is kept in memory and not stored in a database like SimpleCorpus. Corpus function is just SimpleCorpus.
# Corpus automatically removes dashes, underscores, and other punctuations.
# VCorpus does not. Not sure why it's more friendly to being renamed...?
# https://stats.stackexchange.com/questions/164372/what-is-vectorsource-and-vcorpus-in-tm-text-mining-package-in-rus
my_corpus = docRaw
names(my_corpus) = labels

# Preprocessing / cleaning up the phrases for search
my_corpus = tm_map(my_corpus, content_transformer(tolower)) # make everything lowercase
my_corpus = tm_map(my_corpus, content_transformer(removeNumbers)) # remove numbers
my_corpus = tm_map(my_corpus, content_transformer(removePunctuation)) # remove punctuation
my_corpus = tm_map(my_corpus, content_transformer(stripWhitespace)) # remove excess white-space
my_corpus = tm_map(my_corpus, content_transformer(removeWords), stopwords("SMART")) # remove stopwords

# Create Document Term Matrix with Tf-IDF, remove infrequent terms
DTM = DocumentTermMatrix(my_corpus)
DTM = removeSparseTerms(DTM, 0.99)

tfidf_train = weightTfIdf(DTM)

# Dense matrix
X_train = as.matrix(tfidf_train)

```




```{r}
# Prepare test matrix

author_dirs_test = Sys.glob('ReutersC50/C50test/*')

file_list_test = NULL
labels_test = NULL

for(author_test in author_dirs_test) {
  author_name_test = substring(author_test, first=20) # Keep at 20. Train is one letter longer than
  # test, so we need to shorten it here. Otherwise, we get 'sman' instead of 'ssman'.
  files_to_add_test = Sys.glob(paste0(author_test, '/*.txt'))
  file_list_test = append(file_list_test, files_to_add_test)
  labels_test = append(labels_test, rep(author_name_test, length(files_to_add_test)))
}


all_docs_test = lapply(file_list_test, readerPlain) 
all_docsAuthor_test = lapply(file_list, readerPlain) 
names(all_docs_test) = file_list_test
names(all_docs_test) = sub('.txt', '', names(all_docs_test))
names(all_docsAuthor_test) = labels_test

docRaw_test = VCorpus(VectorSource(all_docs_test)) # Again, forced to use Vcorpus
my_corpus_test = docRaw_test
names(my_corpus_test) = labels_test

my_corpus_test = tm_map(my_corpus_test, content_transformer(tolower)) # make everything lowercase
my_corpus_test = tm_map(my_corpus_test, content_transformer(removeNumbers)) # remove numbers
my_corpus_test = tm_map(my_corpus_test, content_transformer(removePunctuation)) # remove punctuation
my_corpus_test = tm_map(my_corpus_test, content_transformer(stripWhitespace)) # remove excess white-space
my_corpus_test = tm_map(my_corpus_test, content_transformer(removeWords), stopwords("SMART")) # remove stop words

DTM_test = DocumentTermMatrix(my_corpus_test)
DTM_test = removeSparseTerms(DTM_test, 0.99)
tfidf_test = weightTfIdf(DTM_test)

X_test = as.matrix(tfidf_test)
```




```{r}

# To account for different words existing in each set, we'll remove words that exist in the test set (but not the training set) and add words that exist in the training set but not the test set. Our training set is of a significant enough size that dropping any such words should have minimal impact. 

# Lists of words from Training Set, Test Set
train_words = colnames(X_train)
test_words = colnames(X_test)

# Create vectors to store words to add / drop
test_add = vector(length = 0)
test_drop = vector(length = 0)

# Find test words that don't exist in training corpus, and vice versa
for (word in test_words) {
  if (!word %in% train_words) {
    test_drop <- c(test_drop, word)
  }
}

for (word in train_words) {
  if (!word %in% test_words) {
    test_add <- c(test_add, word)
  }
}

# Create matrix with zero values for words to add
zero <- matrix(0, nrow = nrow(X_train), ncol=length(test_add))
colnames(zero) <- test_add

# Append test matrix with words to add from train, drop words that don't appear in train
X2_test = cbind(X_test, zero)
X2_test = X2_test[,order(colnames(X2_test))]
X2_test = X2_test[,!colnames(X2_test) %in% test_drop]

```



```{r}

# 1. Naive Bayes 

# Create multinomial probability vector with smoothing
wc = rowsum(X_train + 1/nrow(X_train), labels)
total_wc = rowSums(wc)
w = wc / total_wc
w = log(w)
X2_train = w

# Transpose training matrix, multiply to allow for author comparison, predict author
X2_train = t(X2_train)
log_prob = X2_test %*% X2_train
predict = colnames(log_prob)[max.col(log_prob)]

# Create matrix for comparison
log_prob = cbind(log_prob, predict)
bayesAcc = as.integer(rownames(log_prob) == log_prob[, ncol(log_prob)])
result = cbind.data.frame(rownames(log_prob), predict, bayesAcc)

mean(bayesAcc) # We get 63.4% accuracy 


```




```{r}

# 2. PCR

# Run PC, inspect first two PCs
pc = prcomp(X_train, scale=TRUE, rank.=500)

# plot(pc$x[,1:2], xlab="PCA 1 direction", ylab="PCA 2 direction", bty="n",type='n')
# text(pc$x[,1:2], labels = 1:length(all_docs), cex=0.7)

train_X = X_train %*% pc$rotation
test_X = X2_test %*% pc$rotation
train_y = rownames(X_train)
multi = glmnet(x = train_X, y = train_y, alpha = 0, family = "multinomial")

predict = predict(multi, newx = test_X, type ="class", s=0)
pcrAcc = as.integer(predict == rownames(X2_test))

mean(pcrAcc) # 63.8% accuracy

# Create matrix for comparison
pcr_comp = cbind.data.frame(labels, predict, pcrAcc)

```





```{r}

# Comparing the two models

authors = unique(labels)
n_authors = length(authors)

# Naive Bayes by Author
nb.accuracy = data.frame(matrix(ncol = 2, nrow = n_authors))
colnames(nb.accuracy) = c('author', 'rate')

for (i in 1:49){
  author = authors[i]
  subset = subset(result, result$`rownames(log_prob)` == authors[i])
  nb.accuracy[i,1] = authors[i]
  nb.accuracy[i,2] = mean(subset$bayesAcc)
}

nb.result = nb.accuracy[order(nb.accuracy$rate,decreasing = TRUE),]
hist(nb.result$rate)
nb.result[1:10,]
nb.result[40:50,] # The model was able to predict with 88% accuracy for 10 authors (including 100% accuracy for 3 authors). Overall, it had a fairly spread distribution but skewed toward higher accuracy. It performed well. 


# PCR by Author
pcr.accuracy = data.frame(matrix(ncol = 2, nrow = n_authors))
colnames(pcr.accuracy) = c('author', 'rate')

for (i in 1:49){
  author = authors[i]
  subset = subset(pcr_comp, pcr_comp$labels == authors[i])
  pcr.accuracy[i,1] = authors[i]
  pcr.accuracy[i,2] = mean(subset$pcrAcc)
}

pcr.result = pcr.accuracy[order(pcr.accuracy$rate,decreasing = TRUE),]
hist(pcr.result$rate) 
pcr.result[1:10,]
pcr.result[40:50,]# 

```


### 3. - Association Rule Mining

First, we prepared the data for apriori by stacking it in a matter like the example playlists.csv. We did this by using nested for loops to take each transaction and stack the items purchased in order using the transactions index as an id. Then after removing all the n/a entities created by transactions with less than four items, we were able to shift the data into a dataframe. 

For apriori, we chose 75% confidence as our bar and a support of 0.00125 (as described in notes in our code). This gave us 219 rules which was enough to work with at a max length of 4.  

Plotting the rule sets from apriori using parallels shows the complex relationships formed from the rules, which looks good but isn’t great at conveying the information. Plotting the rules in a “bubble map” selecting only the top 50 rules, like the playlists example, shows the relationships from grocery data in a much clearer manner. 

Finally analyzing the top 10 rules by both confidence and lift, we can see more pertinent correlations.

```{r}
library(tidyverse)
library(arules)  
library(arulesViz)

groceries = read.csv("https://raw.githubusercontent.com/jgscott/STA380/master/data/groceries.txt",header=F, stringsAsFactors = F)
#groceries <- tibble::rowid_to_column(groceries, "TRANSACTION_ID")
#groceries$TRANSACTION_ID = factor(groceries$TRANSACTION_ID)
#Stacking groceries into an indexed data frame similar to the example
groceries2 = matrix(nrow=61184,ncol=2)
i = 1
for(row in 1:nrow(groceries)){
  for(item in groceries[row,]){
    groceries2[i,1] = row
    groceries2[i,2] = item
    i = i +1
  }
}
is.na(groceries2) <- groceries2 == ''
groceries2 = na.omit(groceries2)
groceries2 = as.data.frame(groceries2)
colnames(groceries2) <- c("ID", "Items")
# Preperation for apriori
groceries2$ID = as.factor(groceries2$ID)
grocerylist = split(x=groceries2$Items, f=groceries2$ID)
grocerylist = lapply(grocerylist, unique)

grocerytrans = as(grocerylist, "transactions")
summary(grocerytrans)
#Tried support settings for apiori until we got at least a hundred rules with 75% confidence
groc_rules = apriori(grocerytrans, 
                     parameter=list(support=.000125, confidence=.75, maxlen=4))
groc_rules.df = data.frame(lhs=labels(lhs(groc_rules)),
                           rhs=labels(rhs(groc_rules)),
                           groc_rules@quality)
#Parallel Coordinates Plot
#This graph does a great job of showing off the compelexity of the rules
plot(groc_rules, method="paracoord")

#Bubble map plot for 50 rules
grocsub = subset(groc_rules, subset=confidence > 0.75 & support > 0.000125)
plot(grocsub, method="graph", max=50)

#Find the top10 rules based on lift 
top10lift = groc_rules.df[order(groc_rules.df$lift),]
head(top10lift,n=10)
#Find the top10 rules based of confidence
top10conf = groc_rules.df[order(-groc_rules.df$confidence),]
head(top10conf,n=10)
```


